{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cm6OPFfomn_v"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"labeled_data.json\", \"r\") as f:\n",
        "    labeled_data = json.load(f)\n",
        "\n",
        "with open(\"documents.json\", \"r\") as f:\n",
        "    documents = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into train/val (80%/20%)\n",
        "train_data, val_data = train_test_split(labeled_data, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Train samples: {len(train_data)}, Val samples: {len(val_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xUkQaMZmrTl",
        "outputId": "14b8a441-c1d9-4718-fee0-d3d9f228a3f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 2352, Val samples: 588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(embed_dim * 2, 64),  # Concatenated query+doc embeddings\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, query, doc):\n",
        "        query_embed = self.embedding(query).mean(dim=1)  # Average query embeddings\n",
        "        doc_embed = self.embedding(doc).mean(dim=1)      # Average doc embeddings\n",
        "        combined = torch.cat([query_embed, doc_embed], dim=1)\n",
        "        return self.fc(combined)"
      ],
      "metadata": {
        "id": "qVp38Q_umrWM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrSnAk_pnenh",
        "outputId": "362396cb-7653-456a-9909-90129774ccbc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# --- Define Models ---\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(embed_dim * 2, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, query, doc):\n",
        "        query_embed = self.embedding(query).mean(dim=1)\n",
        "        doc_embed = self.embedding(doc).mean(dim=1)\n",
        "        combined = torch.cat([query_embed, doc_embed], dim=1)\n",
        "        return self.fc(combined)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, doc_ids):  # <-- Requires doc_ids\n",
        "        super().__init__()\n",
        "        self.doc_ids = doc_ids\n",
        "\n",
        "    def forward(self, query, top_k=5):\n",
        "        scores = bm25.get_scores(query.split())\n",
        "        noise = torch.randn(len(scores))\n",
        "        noisy_scores = scores + noise.numpy()\n",
        "        top_indices = noisy_scores.argsort()[-top_k:][::-1]\n",
        "        return [self.doc_ids[i] for i in top_indices]\n",
        "\n",
        "\n",
        "doc_ids = list(documents.keys())  # Get all document IDs\n",
        "corpus = list(documents.values())\n",
        "tokenized_corpus = [doc.split() for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)  # Initialize BM25\n",
        "\n",
        "discriminator = Discriminator(vocab_size=10000)\n",
        "generator = Generator(doc_ids)  # Now correctly initialized with doc_ids\n"
      ],
      "metadata": {
        "id": "RZBPvM-Zoy77"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# Hyperparameters\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Optimizers\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    discriminator.train()\n",
        "\n",
        "    # Shuffle data\n",
        "    np.random.shuffle(labeled_data)\n",
        "\n",
        "    total_d_loss = 0\n",
        "    total_g_loss = 0\n",
        "\n",
        "    for i in tqdm(range(0, len(labeled_data), BATCH_SIZE), desc=f\"Epoch {epoch+1}\"):\n",
        "        batch = labeled_data[i:i+BATCH_SIZE]\n",
        "\n",
        "        # Prepare batch data\n",
        "        real_queries = []\n",
        "        real_docs = []\n",
        "        real_labels = []\n",
        "        fake_docs = []\n",
        "\n",
        "        for query, doc_id, label in batch:\n",
        "            # Real data\n",
        "            real_queries.append(query)\n",
        "            real_docs.append(doc_id)\n",
        "            real_labels.append(label)\n",
        "\n",
        "            # Fake data from generator\n",
        "            fake_doc_id = generator(query)[0]\n",
        "            fake_docs.append(fake_doc_id)\n",
        "\n",
        "        # Convert to tensors with proper shape [batch_size, 1]\n",
        "        real_query_tensors = torch.LongTensor([[hash(q) % 10000] for q in real_queries])\n",
        "        real_doc_tensors = torch.LongTensor([[hash(d) % 10000] for d in real_docs])\n",
        "        fake_doc_tensors = torch.LongTensor([[hash(d) % 10000] for d in fake_docs])\n",
        "        real_labels = torch.FloatTensor(real_labels).unsqueeze(1)  # [batch_size, 1]\n",
        "\n",
        "        # Train Discriminator\n",
        "        d_optimizer.zero_grad()\n",
        "\n",
        "        # Real data loss - ensure inputs are [batch_size, 1]\n",
        "        real_outputs = discriminator(real_query_tensors, real_doc_tensors)\n",
        "        real_loss = criterion(real_outputs, real_labels)\n",
        "\n",
        "        # Fake data loss\n",
        "        fake_outputs = discriminator(real_query_tensors, fake_doc_tensors)\n",
        "        fake_loss = criterion(fake_outputs, torch.zeros_like(fake_outputs))\n",
        "\n",
        "        d_loss = real_loss + fake_loss\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "        total_d_loss += d_loss.item()\n",
        "\n",
        "        # Train Generator (REINFORCE)\n",
        "        sampled_docs = []\n",
        "        for query in real_queries:\n",
        "            sampled_docs.append(generator(query)[0])\n",
        "\n",
        "        # Get rewards from discriminator\n",
        "        with torch.no_grad():\n",
        "            query_tensors = torch.LongTensor([[hash(q) % 10000] for q in real_queries])\n",
        "            doc_tensors = torch.LongTensor([[hash(d) % 10000] for d in sampled_docs])\n",
        "            rewards = discriminator(query_tensors, doc_tensors)\n",
        "\n",
        "        # Generator loss\n",
        "        g_loss = -torch.mean(torch.log(rewards + 1e-8))\n",
        "        total_g_loss += g_loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | D Loss: {total_d_loss/len(labeled_data):.4f} | G Loss: {total_g_loss/len(labeled_data):.4f}\")\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(discriminator, test_data):\n",
        "    discriminator.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for query, doc_id, label in test_data:\n",
        "            # Ensure input shape is [1, 1]\n",
        "            query_tensor = torch.LongTensor([[hash(query) % 10000]])\n",
        "            doc_tensor = torch.LongTensor([[hash(doc_id) % 10000]])\n",
        "\n",
        "            output = discriminator(query_tensor, doc_tensor)\n",
        "            predicted = 1 if output.item() > 0.5 else 0\n",
        "            correct += (predicted == label)\n",
        "            total += 1\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate on test data\n",
        "test_accuracy = evaluate(discriminator, val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK3YkTBgmrbp",
        "outputId": "081c4dab-bac8-4bd7-c534-f90e31d281a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 92/92 [00:11<00:00,  8.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | D Loss: 0.0263 | G Loss: 0.0429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 92/92 [00:09<00:00,  9.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 | D Loss: 0.0215 | G Loss: 0.0573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 92/92 [00:10<00:00,  8.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 | D Loss: 0.0209 | G Loss: 0.0590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 92/92 [00:10<00:00,  8.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 | D Loss: 0.0203 | G Loss: 0.0581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 92/92 [00:10<00:00,  8.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 | D Loss: 0.0199 | G Loss: 0.0594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 92/92 [00:10<00:00,  8.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 | D Loss: 0.0194 | G Loss: 0.0612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 92/92 [00:10<00:00,  8.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 | D Loss: 0.0191 | G Loss: 0.0606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 92/92 [00:09<00:00,  9.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 | D Loss: 0.0186 | G Loss: 0.0627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 92/92 [00:10<00:00,  8.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 | D Loss: 0.0182 | G Loss: 0.0641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 92/92 [00:10<00:00,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 | D Loss: 0.0177 | G Loss: 0.0650\n",
            "Test Accuracy: 0.8129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Create export directory\n",
        "export_dir = \"irgan_model\"\n",
        "os.makedirs(export_dir, exist_ok=True)\n",
        "\n",
        "# Save model state dicts\n",
        "torch.save({\n",
        "    'discriminator_state_dict': discriminator.state_dict(),\n",
        "    'generator_state_dict': generator.state_dict(),\n",
        "    'doc_ids': doc_ids,  # Save document IDs for generator\n",
        "    'vocab_size': 10000,  # Save vocabulary size\n",
        "    'timestamp': datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "}, os.path.join(export_dir, 'irgan_model.pth'))\n",
        "\n",
        "# Save complete models (optional)\n",
        "torch.save(discriminator, os.path.join(export_dir, 'discriminator_full.pth'))\n",
        "torch.save(generator, os.path.join(export_dir, 'generator_full.pth'))\n",
        "\n",
        "print(f\"Models saved to {export_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1ileygBmrfM",
        "outputId": "1c79eda1-b8fe-4329-86e3-60af26739182"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved to irgan_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support, average_precision_score\n",
        "\n",
        "def detailed_evaluate(discriminator, test_data, doc_texts, top_k=5):\n",
        "    discriminator.eval()\n",
        "    results = {\n",
        "        'accuracy': 0,\n",
        "        'precision': [],\n",
        "        'recall': [],\n",
        "        'f1': [],\n",
        "        'average_precision': [],\n",
        "        'top_k_accuracy': 0,\n",
        "        'examples': []\n",
        "    }\n",
        "\n",
        "    total = 0\n",
        "    top_k_correct = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for query, true_doc_id, label in tqdm(test_data, desc=\"Evaluating\"):\n",
        "            # Score all documents for this query\n",
        "            scores = []\n",
        "            for doc_id in doc_ids:\n",
        "                # Tokenize (replace with your actual tokenization)\n",
        "                query_tensor = torch.LongTensor([[hash(query) % 10000]])\n",
        "                doc_tensor = torch.LongTensor([[hash(doc_id) % 10000]])\n",
        "\n",
        "                score = discriminator(query_tensor, doc_tensor).item()\n",
        "                scores.append((doc_id, score))\n",
        "\n",
        "            # Sort by score descending\n",
        "            sorted_docs = sorted(scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            # Top-k accuracy\n",
        "            top_k_ids = [doc_id for doc_id, _ in sorted_docs[:top_k]]\n",
        "            if true_doc_id in top_k_ids:\n",
        "                top_k_correct += 1\n",
        "\n",
        "            # For binary metrics\n",
        "            pred_label = 1 if sorted_docs[0][0] == true_doc_id else 0\n",
        "            results['accuracy'] += (pred_label == label)\n",
        "\n",
        "            # Store for aggregate metrics\n",
        "            all_labels.append(label)\n",
        "            all_scores.append(sorted_docs[0][1])\n",
        "\n",
        "            # Save some examples\n",
        "            if len(results['examples']) < 5:  # Save first 5 examples\n",
        "                results['examples'].append({\n",
        "                    'query': query,\n",
        "                    'true_doc': true_doc_id,\n",
        "                    'true_doc_text': doc_texts.get(true_doc_id, \"\"),\n",
        "                    'predicted_top1': sorted_docs[0][0],\n",
        "                    'predicted_top1_text': doc_texts.get(sorted_docs[0][0], \"\"),\n",
        "                    'top_k': top_k_ids\n",
        "                })\n",
        "\n",
        "            total += 1\n",
        "\n",
        "    # Calculate metrics\n",
        "    results['accuracy'] /= total\n",
        "    results['top_k_accuracy'] = top_k_correct / total\n",
        "\n",
        "    # Precision/Recall/F1\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_labels,\n",
        "        [1 if score > 0.5 else 0 for score in all_scores],\n",
        "        average='binary'\n",
        "    )\n",
        "    results['precision'] = precision\n",
        "    results['recall'] = recall\n",
        "    results['f1'] = f1\n",
        "\n",
        "    # Average Precision\n",
        "    results['average_precision'] = average_precision_score(all_labels, all_scores)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run evaluation\n",
        "doc_texts = {doc_id: text for doc_id, text in zip(doc_ids, corpus)}  # Create doc_id:text mapping\n",
        "eval_results = detailed_evaluate(discriminator, val_data, doc_texts, top_k=5)\n",
        "\n",
        "# Print results\n",
        "print(\"\\n=== Evaluation Results ===\")\n",
        "print(f\"Accuracy: {eval_results['accuracy']:.4f}\")\n",
        "print(f\"Top-{5} Accuracy: {eval_results['top_k_accuracy']:.4f}\")\n",
        "print(f\"Precision: {eval_results['precision']:.4f}\")\n",
        "print(f\"Recall: {eval_results['recall']:.4f}\")\n",
        "print(f\"F1 Score: {eval_results['f1']:.4f}\")\n",
        "print(f\"Average Precision: {eval_results['average_precision']:.4f}\")\n",
        "\n",
        "# Print example predictions\n",
        "print(\"\\n=== Example Predictions ===\")\n",
        "for i, example in enumerate(eval_results['examples']):\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(f\"Query: {example['query']}\")\n",
        "    print(f\"True Document: {example['true_doc']}\")\n",
        "    print(f\"True Doc Text: {example['true_doc_text'][:100]}...\")\n",
        "    print(f\"Predicted Top1: {example['predicted_top1']}\")\n",
        "    print(f\"Predicted Text: {example['predicted_top1_text'][:100]}...\")\n",
        "    print(f\"Top-{5} Predictions: {example['top_k']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkyNheL6msCf",
        "outputId": "21d6ea60-02cb-4cca-957d-41c72115ca05"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 588/588 [00:32<00:00, 18.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Evaluation Results ===\n",
            "Accuracy: 0.7670\n",
            "Top-5 Accuracy: 0.0221\n",
            "Precision: 0.2393\n",
            "Recall: 0.9929\n",
            "F1 Score: 0.3857\n",
            "Average Precision: 0.2080\n",
            "\n",
            "=== Example Predictions ===\n",
            "\n",
            "Example 1:\n",
            "Query: What are the welfare issues associated with feeding housed cattle\n",
            "True Document: https__www_part1\n",
            "True Doc Text: iv • Contents\n",
            "28 Factors Affecting Milk Quality 373 (b) Enzootic bovine leukosis 693\n",
            "R.W.Blowey and ...\n",
            "Predicted Top1: https__www_part182\n",
            "Predicted Text: Neurological Disorders • 897\n",
            "When the lumbosacral site has been surgically pre- arachnoid space.The ...\n",
            "Top-5 Predictions: ['https__www_part182', 'https__www_part129', 'https__www_part58', 'https__www_part61', 'https__www_part142']\n",
            "\n",
            "Example 2:\n",
            "Query: What are the effects of vitamin A toxicity in calves\n",
            "True Document: https__www_part245\n",
            "True Doc Text: 1212 • Index\n",
            "pregnancy (cont’d) prostaglandin(s) pyaemia 737\n",
            "establishment 684–6 breeding synchroniz...\n",
            "Predicted Top1: https__www_part182\n",
            "Predicted Text: Neurological Disorders • 897\n",
            "When the lumbosacral site has been surgically pre- arachnoid space.The ...\n",
            "Top-5 Predictions: ['https__www_part182', 'https__www_part179', 'https__www_part58', 'https__www_part129', 'https__www_part18']\n",
            "\n",
            "Example 3:\n",
            "Query: benefits of all in all out policy for animal farming\n",
            "True Document: https__www_part166\n",
            "True Doc Text: Metabolic Profiles • 817\n",
            "Whitaker,D.A.,Smith,E.J.& Kelly,J.M.(1989) Milk produc- Wilson, J.G. (1966)...\n",
            "Predicted Top1: https__www_part182\n",
            "Predicted Text: Neurological Disorders • 897\n",
            "When the lumbosacral site has been surgically pre- arachnoid space.The ...\n",
            "Top-5 Predictions: ['https__www_part182', 'https__www_part129', 'https__www_part179', 'https__www_part58', 'https__www_part187']\n",
            "\n",
            "Example 4:\n",
            "Query: what is the effect of plane of nutrition on mammary growth in heifers\n",
            "True Document: https__www_part241\n",
            "True Doc Text:  Index\n",
            "abamectin 742,1022,1025,1026,1027, achronchia 177 alkali disease 305\n",
            "1031 acid detergent fibr...\n",
            "Predicted Top1: https__www_part182\n",
            "Predicted Text: Neurological Disorders • 897\n",
            "When the lumbosacral site has been surgically pre- arachnoid space.The ...\n",
            "Top-5 Predictions: ['https__www_part182', 'https__www_part61', 'https__www_part187', 'https__www_part179', 'https__www_part18']\n",
            "\n",
            "Example 5:\n",
            "Query: 862 • Signs of tuberculosis in cattle,\n",
            "True Document: https__www_part242\n",
            "True Doc Text: Index • 1197\n",
            "difficulties 9–10,167 cauda equina syndrome 913 chloramphenicol 217,245,250,252,288,\n",
            "‘d...\n",
            "Predicted Top1: https__www_part142\n",
            "Predicted Text: Viral Diseases • 697\n",
            "neutralization tests have also been described,based on and politics may all be ...\n",
            "Top-5 Predictions: ['https__www_part142', 'https__www_part61', 'https__www_part182', 'https__www_part156', 'https__www_part179']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P7uuP6XYT6Tx"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}